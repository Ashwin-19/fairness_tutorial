# Dealing with Bias and Fairness in Data Science Systems: A Practical Hands-on Tutorial

## Organizers

- Pedro Saleiro, Feedzai
- Kit T. Rodolfa, Carnegie Mellon University
- [Rayid Ghani](http://www.rayidghani.com), Carnegie Mellon University


## Why this tutorial?

Tackling issues of bias and fairness when building and deploying data science systems has received increased attention from the research community in recent years, yet a lot of the research has focused on theoretical aspects and very limited set of application areas and data sets.  There is a lack of 1) practical training materials,  2) methodologies,  and 3) tools for researchers and developers working on real-world algorithmic decisio-nmaking system to deal with issues of bias and fairness.  Today, treating bias and fairness as primary metrics of interest, and building, selecting,and  validating  models  using  those metrics is not standard practice for data scientists. 

## What will we cover?

In this hands-on  tutorial  we will bridge the gap between research and practice, by deep diving into algorithmic fairness, from metrics and definitions to practical case studies, including bias audits (using the [Aequitas toolkit](http://github.com/dssg/aequitas)) and mitigation strategies. By the end of this hands-on tutorial, the audience will be familiar with bias mitigation frameworks and tools to help them making decisions during a project based on intervention and deployment contexts in which their system will be used.

## Schedule and Structure

Part 1:  Background, core concepts and discussion
- Algorithmic decision-making and the role of data scientists.
- Legal and regulatory aspects, public vs private sector conside-ations.
- Understanding potential sources of bias
- Bias and Fairness definitions
- The Fairness Tree - or how to select appropriate metrics depending on actions/interventions
- Bias mitigation approaches and techniques
  - Pre-modeling
  - Model selection
  - Regularization
  - Thresholds
  - Applications
- Additional Case Studies from Social Good Projects

Part 2:  Hands-on bias audit, fairness-aware model selection and case studies
- Intro to Case Study: Prioritize education crowdfunding projects for extra support that may not get funded (using DonorsChoose data)
- Aequitas toolkit overview.
- Bias audit using the Aequitas toolkit
- Results analysis and discussion
- Bias mitigation, re-auditing and model selection
- Additional considerations and conclusions

Part 3: 
- Checklists
- Tools


## Pre-Requisites


## Resources



